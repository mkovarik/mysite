# (09-07) Descriptive Statistics

**Statistics** is the field of study responsible for the analysis of
data. Statistics has broad applications in both science and industry,
and is thus an indispensable skill set for many professionals, from 
business analysts to political scientists.

Over the next few lectures, we introduce **descriptive statistics**.
This is the sub-discipline of statistics responsible for summarizing
**samples**. For now we think of a sample as a known, finite sequence
\\(x_1,x_2,\ldots, x_n\\) of numbers.

**[[ Note:** The term **data set** is sometimes used interchangeably with
sample. This can be problematic. All samples are data sets. Not all data sets
are samples. We will make explicit the difference between the two terms in a
future lecture. **]]**

Descriptive statistics involves calculating quantities called **statistics**
(sometimes called  **descriptive measures**). These are numbers that depend on
the values contained in a given data set. Statistics can provide valuable insight
into the nature of a given data set. Examples of statistics include:

* **Measures of center**: mean, median, mode.
* **Measures of dispersion**: variance, standard deviation, range,
  interquartile range, entropy.
* **Measures of shape:** quartiles/percentiles/quantiles, kurtosis, skewness.
* **Measures of dependence:** linear correlation coefficient, product-moment
  correlation coefficient.

The statistics associated with a sample are known as **sample statistics**. 

## Sample mean

The **sample mean** \\(\bar x \\) (also called an *average*) of a sample \\(x_1,
x_2, \ldots, x_n \\) is a statistic defined by the following formula:

\\[\begin{aligned}
\bar x &= \frac{\sum x_i}{n} \\\\
&= \frac{x_1 + x_2 + \ldots + x_n}{n}.
\end{aligned}\\]

Here, \\(n\\) is the **sample size** (number of items in the sample). 

**[[ Note:** This formula uses [summation notation][sum]. The expression \\(\sum
x_i\\) is equivalent to the sum \\(x_1 + x_2 + \ldots + x_n\\). The Greek letter
Î£ ("sigma") is used to denote the summation of multiple terms. Summation
notation is ubiquitous in mathematics. **]]**

The mean/average is a **measure of center**. Sample points tend to be close to
one or more measures of centrality.

## Sample standard deviation

Points in a sample tend to be close to the sample mean. Of course, closeness is
not a mathematically precise term.

One way to measure closeness is to measure the the **squared deviation** of a given
sample point with the sample mean. The squared deviation of the
\\(i\\)th sample point is defined as \\((x_i - \bar x)^2\\). The further a point is
from the sample mean, the larger the squared deviation.

For example, suppose the sample consists of five numbers: 10, 14, 16, 16, and 18.
The sample mean is

\\[\begin{aligned}
\bar x
&= \frac{10 + 14 + 16 + 16 + 19}{5} \\\\
&= 15.
\end{aligned}\\]

The squared deviations are tabulated below:

<table>
  <tr>
    <td>\(x\)</td>
    <td>\((x - \bar x)^2\)</td>
  </tr>
  <tr>
    <td>10</td>
    <td>25</td>
  </tr>
  <tr>
    <td>14</td>
    <td>1</td>
  </tr>
  <tr>
    <td>16</td>
    <td>1</td>
  </tr>
  <tr>
    <td>16</td>
    <td>1</td>
  </tr>
  <tr>
    <td>19</td>
    <td>16</td>
  </tr>
  <tr>
    <td>Total:</td>
    <td>44</td>
  </tr>
</table>

Here, 44 is the **sum of squared deviations**. This is a rough measure of how much
"dispersion" exists between the sample points. Mathematically, the sum of squared 
deviations is given by the expression \\(\sum (x_i - \bar x)^2\\). 

The sum of squared deviations increases as more data is added to the sample. To
counteract this effect, it is customary to divide the sum of squared variation
by \\(n-1\\), the sample size minus one. The result is the **sample
variance** \\(s^2\\):

\\[s^2 = \frac{1}{n-1} \sum (x_i - \bar x)^2.\\]

In our example, \\(s^2 = \frac{1}{4} \cdot 44 = 11\\).

Another measure of dispersion is the **sample standard deviation** \\(s\\):

\\[\begin{aligned}
s
&= \sqrt{s^2} \\\\
&= \sqrt{\frac{1}{n-1} \sum (x_i - \bar x)^2}
\end{aligned}\\]

In the numerical example, the sample standard deviation is
\\(\sqrt{11} \approx 3.317\\).

Both the sample variance and sample standard deviation are classified as
**measures of dispersion**.

### Robustness

Neither the sample mean nor sample standard deviation are robust. When extreme
values ("outliers") are added to a sample, both statistics will significantly
change. And extreme values may enter the data set via human error. So one should
make sure that a given data set is "error free" before trusting the sample mean
or sample standard deviation as being accurate.

A **robust statistic** is a statistic that is insensitive to when extreme values
enters a data set. Examples of robust statistics include the median (a measure
of center) and the interquartile range (a measure of dispersion). These
statistics will be discussed next lecture.

## Homework (complete before 09-12)

1. Complete "Assignment 01" in MyStatLab.
2. The file [gpa.txt](static/gpa.txt) contains a
   [stem-and-leaf diagram][sl] displaying the grade point
   averages (GPAs) of a sample of twenty students. Calculate
   the sample mean, variance, and standard deviation.
  *Challenge mode*: calculate the sample mean and variance
  by hand. (Answer: <span class="spoiler">mean=2.97, variance =
  1.324, standard deviation =1.151</span>)
3. Read the following sections from the course text: 3.1, 3.2, 3.4,
   2.3, 2.4, 2.5.
4. Complete the course [survey][survey].

[sl]: https://en.wikipedia.org/wiki/Stem-and-leaf_display
[sum]: https://en.wikipedia.org/wiki/Summation
[survey]: https://goo.gl/forms/XUuqlTk7s6Hg9h642
