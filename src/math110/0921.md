# Probability Theory II

Much of probability theory owes itself to mathematicians analyzing games
of chance. Pictured below is a 20-sided die ("d20") originating in Egypt
about 2000 or so years ago.

![](static/d20.jpg)

(Source: [Metropolitan Meuseum of Art][metro])

## Interpretation of probability

**Probability** is a measure of uncertainty. It is a number ranging from
0 to 1. An event that is gauranteed to happen has a probability of 1.
An event that can never happen have a probability of 0. Higher
probabilities correspond to a higher likelihood of occurrence.

Under the **frequentist interpretation**, probabilities can be
interpreted as the "long-term frequency" of an event occurring. Suppose
one is able to run an unlimited number of independent and identical
experiments. In each experiment, it is observed whether or not a given
event occurs. The **relative frequency** of the event is defined as
the following ratio:

\\[\frac{\text{number of times an event occurs}}
{\text{number of experiments}}.\\]

As more experiments are performed, the value of this ratio will *eventually*
converge to some number between 0 and 1. This number is defined as the
probability of the event.

An alternative interpretation is the [Bayesian interpretation][bwik], which
views probability as measuring  a *degree of confidence* of an event
occurrence.

A statistician's personal interpretation of probability does affect the
statistical methodologies they prefer. Bayesian statistics is very different
than frequentist statistics. In this class, we cover frequentist methods
(even though I am personally a Bayesian). Frequentist methods tend to be
simpler than their Bayesian alternatives.

## Outcomes

A random process produces random **outcomes**. When conducting analysis
with probabilities, it is important the set (collection) of possible
outcomes. The outcomes should be **mutually exclusive** (no two outcomes
can occur simulteneously). 

If possible, it is convenient to define the outcome of a random process
in such a way so that each outcome is equally likely. The **probability**
of each outcome is then defined as \\( 1 / n \\), where \\(n\\) is the
number of possible outcomes. 

Some examples of outcome spaces with equal probabilities:

* Flipping a balanced coin is associated with the outcome space
  \\(\\{H, T\\}\\). The probabilites of each outcome is 1/2.
* Casting a balanced six-sided die is associated with the outcome
  space \\(\\{1, 2, 3, 4, 5, 6\\}\\). The probabilities associated
  with each outcome is 1/6.
* Flipping two balanced coins (or flipping one balanced coin twice)
  produces an outcome space with 4 outcomes: \\(\\{HH, HT, TH, TT\\}\\).
  The probabilities of each outcome is 1/4.
* Casting two balanced six-sided dice (or casting one balanced six
  sided die twice) similarly produces 36 possible outcomes.
* A simple random sample (with or without replacement) produces samples
  of equal probabilities. The number of possible samples, however,
  is innumerable. For example, sampling 10 items from a population of
  100 results in up to about 17 trillion possible samples (without
  replacement).

Not all random processes produce equally-likely outcomes. For example,
an unbalanced coin or die will produce outcomes that have different
probabilities. Flipping a coin may produce a heads 60% of the time
and a tails 40% of the time.

## Events

An **event** is a set (collection) of possible outcomes. Events can be
assigned probabilities as well. For example, if each outcome is equally
likely, then probability of an event is defined as the following ratio:

\\[
\text{probability of an event}
= \frac{\text{number of outcomes in events}}
{\text{number of possible outcomes}}.
\\]

**Example.** Suppose we roll a balanced, ten-sided die. The outcome space
is \\(\\{1,2,3,4,5,6, 7, 8, 9, 10\\}\\). There are 10 possible outcomes,
all equally likely. The prime numbers less than 10 are \\(\\{2,3,5,7\\}\\).
The probability of rolling a prime number is therefore 4/10. ■ 


**Example.** In the game *Catan*, two balanced, six-sided die are rolled.
The outcomes of each die are added together. The result determines which
player receives what receive. Suppose we wish to determine the probability
that the sum of the two die will be 8 when they are next cast. Looking at
the following table, there are exactly 5 ways for this to occur:

```
   1   2   3   4   5   6
  *---------------------
1 |2   3   4   5   6   7
2 |3   4   5   6   7   8
3 |4   5   6   7   8   9
4 |5   6   7   8   9  10
5 |6   7   8   9   10 11
6 |7   8   9   10  11 12
```
The probability of the sum of each die roll being 8 occuring is
therefore 5/36. ■ 

Note that this formula works *only* works for spaces with equal likelihood.
For finite (or countably infinite) outcome spaces that may or may not have
equaly likely outcomes, the following formula is used:

\\[
\text{probability of an event}
= \sum \text{probability of each outcome}.
\\]

**[[Note:** If the outcome space is "continuous", there is an entirely
different formula for computing probabilities:

\\[
\text{probability of event }A = \int_{A} p(x) dx.
\\]

Here, \\(p(x)\\) is the "probability density function" associated with
the random process. If you haven't taken calculus, don't worry too
much about this formula. **]]**

## Combining Events

It is possible to combine multiple events to obtain a new event. These
are done via **set-theoretic operations**:

* The **complement** (or **negation**) of an event consists of all possible
  outcomes not in the event. The complement of an event \\(A\\) is denoted
  as \\(\text{not } A\\) or as \\(A^{c}\\).
* The **intersection** of two events consists of all possible outcomes
  in *both* the events. The intersection of two events \\(A\\) and \\(B\\)
  is denoted as \\(A \text{ and } B \\), or as \\( A \text{ \\& } B \\) ,
  or as \\(A \cap B \\), or as \\(AB\\).
* The **union** of two events consists of all possible outcomes in *either* or
  *both* events. The intersection of two events \\(A\\) and \\(B\\) is denoted
  as \\(A \text{ or } B\\) or as \\(A \cup B\\).


Multiple of these operations can be combined to form complicated expressions.
For example, \\(C \text{ or } (A \text{ \\& } B)\\) consists of all outcomes
either in \\(C\\) or in both \\(A\\) and \\(B\\).

See the homework for examples of combining events.

[bwik]: https://en.wikipedia.org/wiki/Bayesian_probability
[metro]: http://www.metmuseum.org/art/collection/search/551072